{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.3.1-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.conda/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Collecting sympy (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.3.1 (from torch)\n",
      "  Using cached triton-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Using cached torch-2.3.1-cp311-cp311-manylinux1_x86_64.whl (779.2 MB)\n",
      "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Using cached triton-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
      "Using cached filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
      "Installing collected packages: mpmath, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch\n",
      "Successfully installed MarkupSafe-2.1.5 filelock-3.15.4 fsspec-2024.6.1 jinja2-3.1.4 mpmath-1.3.0 networkx-3.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 sympy-1.13.1 torch-2.3.1 triton-2.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. GPU is present.\n",
      "Device name: NVIDIA GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. GPU is present.\")\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA is not available. No GPU detected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Using cached numpy-2.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Using cached numpy-2.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.3 MB)\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.53.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (162 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in ./.conda/lib/python3.11/site-packages (from matplotlib) (2.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.conda/lib/python3.11/site-packages (from matplotlib) (24.1)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.conda/lib/python3.11/site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Using cached matplotlib-3.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "Using cached contourpy-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (306 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.53.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "Using cached kiwisolver-1.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "Using cached pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "Using cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.2.1 cycler-0.12.1 fonttools-4.53.1 kiwisolver-1.4.5 matplotlib-3.9.1 pillow-10.4.0 pyparsing-3.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[0.0191, 0.0739],\n",
      "        [0.7551, 0.3018],\n",
      "        [0.1049, 0.8480]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(3,2)\n",
    "print(x)\n",
    "x = torch.zeros(3,2)\n",
    "print(x)\n",
    "x = torch.rand(3,2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.0374e+22, 1.3563e-19],\n",
      "        [2.7953e+20, 7.1321e+28],\n",
      "        [1.5791e-19, 2.7381e+20]])\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(3,2)\n",
    "print(x)\n",
    "y = torch.zeros_like(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2],\n",
    "                  [3, 4],\n",
    "                  [5,6]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n",
      "tensor([2, 4, 6])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())\n",
    "print(x[:,1])\n",
    "print(x[0:2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x[1,1]\n",
    "print(y.item())\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "y = x.view(2,3)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4],\n",
       "        [5],\n",
       "        [6]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.view(6,-1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2.],\n",
      "        [2., 2.],\n",
      "        [2., 2.]]) tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]]) tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(3,2)\n",
    "y = torch.ones(3,2)\n",
    "z1 = x+y\n",
    "z2 = x-y\n",
    "z3 = x*y\n",
    "print(z1,z2, z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2.],\n",
      "        [2., 2.],\n",
      "        [2., 2.]]) tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "z = y.add(x)\n",
    "print(z, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2.],\n",
      "        [2., 2.],\n",
      "        [2., 2.]]) tensor([[2., 2.],\n",
      "        [2., 2.],\n",
      "        [2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "z = y.add_(x)\n",
    "print(z, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x_np = x.numpy()\n",
    "print(type(x), type(x_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "a = np.random.randn(5)\n",
    "a_pt = torch.from_numpy(a)\n",
    "print(type(a), type(a_pt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.38664202 0.34430232 2.34207494 2.22866643 3.10133463]\n",
      "tensor([3.3866, 0.3443, 2.3421, 2.2287, 3.1013], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "np.add(a, 1,out=a)\n",
    "print(a)\n",
    "print(a_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUDA Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.cuda.device object at 0x7acfa4e268d0>\n",
      "NVIDIA GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda0 = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2.],\n",
      "        [2., 2.],\n",
      "        [2., 2.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(3,2,device=cuda0)\n",
    "b = torch.ones(3,2,device=cuda0)\n",
    "c = a+b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audo diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones([3,2], requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6., 6.],\n",
      "        [6., 6.],\n",
      "        [6., 6.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x+5\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[37., 37.],\n",
      "        [37., 37.],\n",
      "        [37., 37.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y*y + 1\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.sum(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12., 12.],\n",
      "        [12., 12.],\n",
      "        [12., 12.]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$t = \\sum_i z_i, z_i = y_i^2 + 1, y_i = x_i + 5$\n",
    "\n",
    "$\\frac{\\partial t}{\\partial x_i} = \\frac{\\partial z_i}{\\partial x_i} = \\frac{\\partial z_i}{\\partial y_i} \\frac{\\partial y_i}{\\partial x_i} = 2y_i \\times 1$\n",
    "\n",
    "At x = 1, y = 6, $\\frac{\\partial t}{\\partial x_i} = 12$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9975, 0.9975],\n",
      "        [0.9975, 0.9975],\n",
      "        [0.9975, 0.9975]], grad_fn=<MulBackward0>)\n",
      "tensor([[0.0025, 0.0025],\n",
      "        [0.0025, 0.0025],\n",
      "        [0.0025, 0.0025]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones([3,2], requires_grad=True)\n",
    "y = x + 5\n",
    "y.retain_grad()\n",
    "r = 1/(1 + torch.exp(-y))\n",
    "r.retain_grad()\n",
    "print(r)\n",
    "s = torch.sum(r)\n",
    "s.backward()\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0025, 0.0025],\n",
      "        [0.0025, 0.0025],\n",
      "        [0.0025, 0.0025]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones([3, 2], requires_grad=True)\n",
    "y = x + 5\n",
    "r = 1/(1 + torch.exp(-y))\n",
    "a = torch.ones([3, 2])\n",
    "r.backward(a)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(166.5213, grad_fn=<SumBackward0>)\n",
      "tensor([-11.6889]) tensor([103.2216])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn([20,1], requires_grad=True)\n",
    "y = 3*x - 2\n",
    "\n",
    "w = torch.tensor([1.0], requires_grad=True)\n",
    "b = torch.tensor([1.0], requires_grad=True)\n",
    "\n",
    "y_hat = w*x + b\n",
    "\n",
    "loss = torch.sum((y_hat-y)**2)\n",
    "\n",
    "print(loss)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print(w.grad, b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0\n",
      "tensor(256.9986, grad_fn=<SumBackward0>)\n",
      "1.8257310390472412 -0.16283631324768066\n",
      "tensor(119.5798, grad_fn=<SumBackward0>)\n",
      "2.4599051475524902 -1.0592750310897827\n",
      "tensor(32.5803, grad_fn=<SumBackward0>)\n",
      "2.853238344192505 -1.526116132736206\n",
      "tensor(5.3117, grad_fn=<SumBackward0>)\n",
      "2.9382731914520264 -1.7239577770233154\n",
      "tensor(1.7207, grad_fn=<SumBackward0>)\n",
      "2.9848151206970215 -1.838219165802002\n",
      "tensor(0.5243, grad_fn=<SumBackward0>)\n",
      "2.98714280128479 -1.9028141498565674\n",
      "tensor(0.2029, grad_fn=<SumBackward0>)\n",
      "3.000384569168091 -1.9428268671035767\n",
      "tensor(0.0655, grad_fn=<SumBackward0>)\n",
      "2.9974100589752197 -1.9657145738601685\n",
      "tensor(0.0245, grad_fn=<SumBackward0>)\n",
      "3.001366138458252 -1.9796901941299438\n",
      "tensor(0.0080, grad_fn=<SumBackward0>)\n",
      "3.0027287006378174 -1.9876906871795654\n",
      "tensor(0.0030, grad_fn=<SumBackward0>)\n",
      "3.002480983734131 -1.9924695491790771\n",
      "tensor(0.0010, grad_fn=<SumBackward0>)\n",
      "3.0027222633361816 -1.9952675104141235\n",
      "tensor(0.0008, grad_fn=<SumBackward0>)\n",
      "3.000872850418091 -1.9976011514663696\n",
      "tensor(0.0002, grad_fn=<SumBackward0>)\n",
      "2.9999587535858154 -1.9987118244171143\n",
      "tensor(3.3954e-05, grad_fn=<SumBackward0>)\n",
      "3.0001561641693115 -1.9992326498031616\n",
      "tensor(1.3282e-05, grad_fn=<SumBackward0>)\n",
      "3.0000264644622803 -1.9995524883270264\n",
      "tensor(4.1701e-06, grad_fn=<SumBackward0>)\n",
      "2.999957323074341 -1.9997347593307495\n",
      "tensor(1.2320e-06, grad_fn=<SumBackward0>)\n",
      "2.999925374984741 -1.9998328685760498\n",
      "tensor(6.4823e-07, grad_fn=<SumBackward0>)\n",
      "2.9999494552612305 -1.9998996257781982\n",
      "tensor(2.7042e-07, grad_fn=<SumBackward0>)\n",
      "2.9999704360961914 -1.9999430179595947\n",
      "tensor(7.6203e-08, grad_fn=<SumBackward0>)\n",
      "2.99997878074646 -1.9999654293060303\n",
      "tensor(3.3378e-08, grad_fn=<SumBackward0>)\n",
      "2.9999871253967285 -1.9999797344207764\n",
      "tensor(1.0232e-08, grad_fn=<SumBackward0>)\n",
      "2.9999916553497314 -1.9999868869781494\n",
      "tensor(4.4428e-09, grad_fn=<SumBackward0>)\n",
      "2.9999935626983643 -1.9999923706054688\n",
      "tensor(1.6465e-09, grad_fn=<SumBackward0>)\n",
      "2.9999947547912598 -1.9999955892562866\n",
      "tensor(8.9402e-10, grad_fn=<SumBackward0>)\n",
      "2.9999966621398926 -1.9999974966049194\n",
      "tensor(3.1352e-10, grad_fn=<SumBackward0>)\n",
      "2.999997615814209 -1.999998688697815\n",
      "tensor(9.3920e-11, grad_fn=<SumBackward0>)\n",
      "2.999998092651367 -1.9999991655349731\n",
      "tensor(6.9292e-11, grad_fn=<SumBackward0>)\n",
      "2.9999988079071045 -1.9999990463256836\n",
      "tensor(3.0525e-11, grad_fn=<SumBackward0>)\n",
      "2.9999992847442627 -1.9999991655349731\n",
      "tensor(3.3836e-11, grad_fn=<SumBackward0>)\n",
      "2.999999761581421 -1.9999996423721313\n",
      "tensor(5.2864e-12, grad_fn=<SumBackward0>)\n",
      "3.0 -1.999999761581421\n",
      "tensor(1.1369e-12, grad_fn=<SumBackward0>)\n",
      "3.0 -1.9999998807907104\n",
      "tensor(2.7001e-13, grad_fn=<SumBackward0>)\n",
      "3.0 -1.9999998807907104\n",
      "tensor(1.0516e-12, grad_fn=<SumBackward0>)\n",
      "3.0 -1.9999998807907104\n",
      "tensor(3.8369e-13, grad_fn=<SumBackward0>)\n",
      "3.0 -1.9999998807907104\n",
      "tensor(4.9738e-13, grad_fn=<SumBackward0>)\n",
      "3.0 -1.9999998807907104\n",
      "tensor(4.8317e-13, grad_fn=<SumBackward0>)\n",
      "3.0 -1.9999998807907104\n",
      "tensor(3.8369e-13, grad_fn=<SumBackward0>)\n",
      "3.0 -1.9999998807907104\n",
      "tensor(2.5580e-13, grad_fn=<SumBackward0>)\n",
      "3.0 -1.9999998807907104\n",
      "tensor(6.9633e-13, grad_fn=<SumBackward0>)\n",
      "3.0 -1.9999998807907104\n",
      "tensor(4.4054e-13, grad_fn=<SumBackward0>)\n",
      "3.0 -1.9999998807907104\n",
      "tensor(6.9633e-13, grad_fn=<SumBackward0>)\n",
      "3.0 -1.9999998807907104\n",
      "tensor(2.1316e-13, grad_fn=<SumBackward0>)\n",
      "3.0 -1.9999998807907104\n",
      "tensor(2.1316e-13, grad_fn=<SumBackward0>)\n",
      "3.0 -1.9999998807907104\n",
      "tensor(5.2580e-13, grad_fn=<SumBackward0>)\n",
      "3.0 -1.9999998807907104\n",
      "tensor(4.1211e-13, grad_fn=<SumBackward0>)\n",
      "3.0 -1.9999998807907104\n",
      "tensor(3.2685e-13, grad_fn=<SumBackward0>)\n",
      "3.0 -1.9999998807907104\n",
      "tensor(3.8369e-13, grad_fn=<SumBackward0>)\n",
      "3.0 -1.9999998807907104\n",
      "tensor(1.7053e-13, grad_fn=<SumBackward0>)\n",
      "3.0 -1.9999998807907104\n",
      "tensor(2.4158e-13, grad_fn=<SumBackward0>)\n",
      "3.0 -1.9999998807907104\n",
      "tensor(2.4158e-13, grad_fn=<SumBackward0>)\n",
      "3.0 -1.9999998807907104\n",
      "tensor(7.2475e-13, grad_fn=<SumBackward0>)\n",
      "3.0 -1.9999998807907104\n",
      "tensor(2.8422e-13, grad_fn=<SumBackward0>)\n",
      "3.0 -1.9999998807907104\n",
      "tensor(1.4211e-13, grad_fn=<SumBackward0>)\n",
      "3.0 -1.9999998807907104\n",
      "tensor(2.1316e-13, grad_fn=<SumBackward0>)\n",
      "3.0 -1.9999998807907104\n",
      "tensor(2.5580e-13, grad_fn=<SumBackward0>)\n",
      "3.0 -1.9999998807907104\n",
      "tensor(1.2221e-12, grad_fn=<SumBackward0>)\n",
      "3.0 -1.9999998807907104\n",
      "tensor(3.6948e-13, grad_fn=<SumBackward0>)\n",
      "3.0 -1.9999998807907104\n",
      "tensor(4.4054e-13, grad_fn=<SumBackward0>)\n",
      "3.0 -1.9999998807907104\n",
      "tensor(2.4158e-13, grad_fn=<SumBackward0>)\n",
      "3.0 -1.9999998807907104\n",
      "tensor(4.4054e-13, grad_fn=<SumBackward0>)\n",
      "3.0 -1.9999998807907104\n",
      "tensor(5.5422e-13, grad_fn=<SumBackward0>)\n",
      "3.0 -1.9999998807907104\n",
      "tensor(3.2685e-13, grad_fn=<SumBackward0>)\n",
      "3.0 -1.9999998807907104\n",
      "tensor(4.8317e-13, grad_fn=<SumBackward0>)\n",
      "3.0 -1.9999998807907104\n",
      "tensor(1.5490e-12, grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n",
      "tensor(0., grad_fn=<SumBackward0>)\n",
      "3.0 -2.0\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "w = torch.tensor([1.0], requires_grad=True)\n",
    "b = torch.tensor([1.0], requires_grad=True)\n",
    "\n",
    "print(w.item(), b.item())\n",
    "\n",
    "for i in range(100):\n",
    "    x = torch.randn([20, 1])\n",
    "    y = 3*x-2\n",
    "\n",
    "    y_hat = w*x + b\n",
    "    loss = torch.sum((y_hat-y)**2)\n",
    "    print(loss)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate*w.grad\n",
    "        b -= learning_rate*b.grad\n",
    "\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "    \n",
    "    print(w.item(), b.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(31.6901, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(30.7045, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(29.7603, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(28.8556, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(27.9886, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(27.1579, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(26.3618, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(25.5987, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(24.8674, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(24.1663, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(23.4942, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(22.8499, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(22.2320, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(21.6396, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(21.0714, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(20.5265, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(20.0038, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(19.5024, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(19.0213, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(18.5597, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(18.1166, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(17.6915, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(17.2833, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(16.8915, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(16.5153, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(16.1541, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(15.8071, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(15.4738, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(15.1536, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(14.8459, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(14.5502, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(14.2659, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(13.9927, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(13.7299, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(13.4772, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(13.2341, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(13.0002, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(12.7752, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(12.5585, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(12.3500, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(12.1491, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(11.9557, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(11.7693, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(11.5897, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(11.4166, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(11.2497, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(11.0888, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(10.9335, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(10.7837, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(10.6391, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(10.4995, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(10.3647, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(10.2344, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(10.1086, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(9.9869, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(9.8693, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(9.7555, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(9.6454, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(9.5389, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(9.4357, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(9.3358, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(9.2390, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(9.1451, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(9.0541, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(8.9659, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(8.8802, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(8.7971, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(8.7164, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(8.6380, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(8.5617, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(8.4877, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(8.4156, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(8.3455, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(8.2772, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(8.2108, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(8.1461, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(8.0830, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(8.0215, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(7.9615, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(7.9030, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(7.8458, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(7.7900, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(7.7355, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(7.6822, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(7.6301, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(7.5792, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(7.5293, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(7.4805, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(7.4327, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(7.3859, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(7.3400, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(7.2950, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(7.2509, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(7.2076, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(7.1651, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(7.1233, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(7.0823, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(7.0420, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(7.0024, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(6.9635, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(6.9251, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(6.8874, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(6.8503, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(6.8137, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(6.7777, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(6.7422, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(6.7073, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(6.6728, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(6.6388, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(6.6052, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(6.5721, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(6.5394, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(6.5071, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(6.4752, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(6.4437, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(6.4126, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(6.3818, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(6.3514, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(6.3213, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(6.2915, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(6.2620, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(6.2329, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(6.2041, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(6.1755, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(6.1472, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(6.1192, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(6.0914, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(6.0639, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(6.0367, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(6.0097, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.9829, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.9563, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.9300, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.9039, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.8780, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.8523, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.8268, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.8015, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.7764, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.7514, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.7267, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.7021, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.6777, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.6535, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.6294, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.6055, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.5817, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.5581, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.5347, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.5114, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.4882, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.4652, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.4423, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.4196, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.3970, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.3745, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.3521, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.3299, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.3078, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.2859, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.2640, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.2423, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.2207, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.1992, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.1778, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.1565, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.1354, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.1143, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.0934, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.0725, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.0518, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.0311, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(5.0106, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.9902, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.9699, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.9496, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.9295, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.9094, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.8895, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.8696, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.8499, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.8302, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.8106, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.7912, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.7718, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.7525, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.7332, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.7141, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.6951, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.6761, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.6572, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.6384, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.6197, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.6011, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.5825, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.5641, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.5457, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.5274, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.5092, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.4910, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.4729, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.4550, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.4370, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.4192, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.4014, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.3838, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.3661, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.3486, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.3311, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.3138, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.2964, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.2792, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.2620, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.2449, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.2279, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.2109, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.1941, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.1772, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.1605, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.1438, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.1272, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.1107, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.0942, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.0778, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.0614, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.0452, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.0290, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(4.0128, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.9968, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.9808, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.9648, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.9489, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.9331, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.9174, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.9017, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.8861, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.8705, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.8551, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.8396, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.8243, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.8090, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.7937, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.7785, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.7634, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.7484, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.7334, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.7184, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.7036, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.6887, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.6740, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.6593, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.6447, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.6301, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.6156, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.6011, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.5867, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.5724, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.5581, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.5439, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.5297, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.5156, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.5015, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.4875, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.4736, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.4597, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.4459, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.4321, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.4184, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.4047, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.3911, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.3775, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.3640, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.3506, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.3372, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.3238, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.3106, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.2973, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.2841, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.2710, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.2579, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.2449, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.2319, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.2190, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.2062, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.1933, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.1806, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.1679, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.1552, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.1426, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.1300, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.1175, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.1051, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.0927, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.0803, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.0680, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.0557, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.0435, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.0314, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.0192, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(3.0072, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.9952, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.9832, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.9713, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.9594, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.9476, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.9358, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.9240, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.9124, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.9007, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.8891, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.8776, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.8661, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.8546, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.8432, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.8319, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.8205, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.8093, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.7980, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.7869, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.7757, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.7646, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.7536, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.7426, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.7316, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.7207, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.7098, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.6990, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.6882, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.6775, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.6668, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.6561, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.6455, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.6349, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.6244, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.6139, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.6035, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.5931, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.5827, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.5724, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.5621, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.5519, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.5417, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.5315, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.5214, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.5113, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.5013, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.4913, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.4813, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.4714, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.4615, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.4517, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.4419, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.4322, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.4224, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.4128, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.4031, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.3935, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.3839, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.3744, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.3649, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.3555, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.3461, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.3367, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.3274, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.3181, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.3088, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.2996, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.2904, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.2812, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.2721, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.2630, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.2540, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.2450, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.2360, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.2271, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.2182, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.2093, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.2005, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.1917, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.1829, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.1742, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.1655, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.1569, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.1482, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.1397, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.1311, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.1226, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.1141, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.1057, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.0973, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.0889, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.0805, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.0722, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.0639, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.0557, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.0475, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.0393, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.0311, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.0230, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.0149, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(2.0069, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.9989, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.9909, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.9829, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.9750, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.9671, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.9592, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.9514, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.9436, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.9359, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.9281, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.9204, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.9127, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.9051, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.8975, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.8899, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.8823, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.8748, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.8673, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.8599, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.8524, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.8450, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.8377, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.8303, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.8230, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.8157, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.8085, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.8012, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.7940, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.7869, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.7797, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.7726, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.7655, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.7585, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.7515, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.7445, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.7375, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.7305, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.7236, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.7167, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.7099, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.7030, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.6962, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.6895, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.6827, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.6760, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.6693, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.6626, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.6560, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.6494, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.6428, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.6362, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.6297, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.6232, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.6167, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.6102, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.6038, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.5974, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.5910, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.5846, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.5783, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.5720, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.5657, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.5594, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.5532, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.5470, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.5408, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.5347, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.5285, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.5224, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.5163, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.5103, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.5043, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.4982, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.4923, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.4863, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.4804, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.4744, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.4685, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.4627, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.4568, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.4510, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.4452, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.4394, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.4337, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.4280, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.4222, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.4166, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.4109, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.4053, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.3997, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.3941, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.3885, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.3829, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.3774, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.3719, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.3664, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.3610, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.3555, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.3501, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.3447, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.3393, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.3340, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.3287, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.3234, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.3181, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.3128, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.3075, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.3023, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.2971, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.2919, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.2868, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.2816, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.2765, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.2714, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.2663, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.2613, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.2562, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.2512, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.2462, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.2412, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.2363, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.2313, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.2264, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.2215, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.2166, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.2118, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.2069, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.2021, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.1973, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.1925, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.1877, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.1830, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.1783, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.1736, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.1689, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.1642, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.1596, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.1549, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.1503, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.1457, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.1411, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.1366, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.1320, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.1275, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.1230, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.1185, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.1140, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.1096, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.1052, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.1007, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.0963, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.0920, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.0876, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.0833, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.0789, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.0746, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.0703, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.0660, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.0618, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.0575, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.0533, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.0491, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.0449, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.0407, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.0366, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.0324, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.0283, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.0242, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.0201, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.0160, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.0120, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.0079, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(1.0039, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.9999, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.9959, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.9919, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.9879, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.9840, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.9801, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.9762, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.9723, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.9684, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.9645, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.9606, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.9568, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.9530, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.9492, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.9454, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.9416, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.9378, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.9341, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.9304, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.9266, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.9229, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.9192, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.9156, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.9119, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.9083, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.9046, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.9010, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.8974, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.8938, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.8903, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.8867, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.8832, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.8796, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.8761, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.8726, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.8691, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.8657, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.8622, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.8588, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.8553, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.8519, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.8485, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.8451, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.8417, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.8384, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.8350, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.8317, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.8284, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.8251, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.8218, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.8185, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.8152, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.8119, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.8087, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.8055, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.8023, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.7990, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.7959, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.7927, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.7895, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.7863, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.7832, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.7801, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.7770, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.7739, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.7708, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.7677, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.7646, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.7616, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.7585, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.7555, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.7525, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.7495, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.7465, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.7435, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.7405, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.7376, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.7346, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.7317, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.7287, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.7258, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.7229, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.7200, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.7172, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.7143, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.7114, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.7086, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.7058, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.7030, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.7001, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6973, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6946, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6918, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6890, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6863, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6835, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6808, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6781, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6754, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6727, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6700, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6673, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6646, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6620, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6593, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6567, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6541, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6515, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6489, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6463, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6437, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6411, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6385, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6360, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6335, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6309, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6284, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6259, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6234, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6209, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6184, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6159, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6135, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6110, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6086, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6062, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6037, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.6013, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5989, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5965, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5941, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5918, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5894, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5870, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5847, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5824, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5800, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5777, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5754, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5731, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5708, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5685, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5663, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5640, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5618, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5595, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5573, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5550, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5528, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5506, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5484, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5462, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5440, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5419, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5397, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5375, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5354, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5333, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5311, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5290, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5269, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5248, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5227, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5206, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5185, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5165, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5144, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5123, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5103, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5082, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5062, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5042, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5022, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.5002, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4982, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4962, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4942, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4922, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4903, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4883, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4863, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4844, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4825, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4805, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4786, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4767, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4748, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4729, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4710, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4691, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4673, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4654, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4635, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4617, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4598, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4580, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4562, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4543, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4525, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4507, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4489, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4471, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4453, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4436, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4418, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4400, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4383, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4365, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4348, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4330, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4313, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4296, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4279, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4261, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4244, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4227, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4211, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4194, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4177, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4160, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4144, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4127, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4111, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4094, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4078, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4062, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4045, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4029, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.4013, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3997, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3981, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3965, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3949, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3934, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3918, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3902, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3887, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3871, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3856, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3840, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3825, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3810, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3794, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3779, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3764, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3749, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3734, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3719, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3704, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3689, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3675, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3660, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3645, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3631, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3616, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3602, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3587, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3573, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3559, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3545, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3530, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3516, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3502, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3488, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3474, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3460, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3447, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3433, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3419, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3406, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3392, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3378, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3365, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3351, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3338, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3325, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3311, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3298, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3285, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3272, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3259, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3246, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3233, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3220, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3207, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3194, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3181, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3169, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3156, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3143, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3131, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3118, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3106, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3093, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3081, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3069, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3057, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3044, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3032, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3020, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.3008, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2996, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2984, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2972, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2960, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2948, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2937, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2925, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2913, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2902, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2890, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2878, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2867, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2855, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2844, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2833, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2821, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2810, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2799, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2788, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2776, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2765, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2754, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2743, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2732, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2721, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2711, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2700, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2689, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2678, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2668, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2657, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2646, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2636, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2625, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2615, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2604, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2594, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2583, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2573, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2563, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2553, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2542, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2532, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2522, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2512, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2502, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2492, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2482, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2472, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2462, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2452, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2443, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2433, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2423, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2413, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2404, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2394, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2385, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2375, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2366, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2356, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2347, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2337, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2328, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2319, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2309, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2300, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2291, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2282, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2273, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2264, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2255, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2246, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2237, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2228, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2219, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2210, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2201, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2192, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2184, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2175, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2166, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2157, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2149, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2140, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2132, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2123, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2115, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2106, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2098, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2089, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2081, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2073, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2065, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2056, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2048, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2040, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2032, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2024, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2016, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.2007, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.1999, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.1991, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.1983, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.1976, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.1968, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.1960, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.1952, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.1944, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.1936, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.1929, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.1921, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.1913, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.1906, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.1898, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.1890, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.1883, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.1875, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.1868, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.1860, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.1853, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.1846, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.1838, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.1831, grad_fn=<SumBackward0>)\n",
      "torch.Size([10])\n",
      "torch.Size([10])\n",
      "loss tensor(0.1824, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "N = 10\n",
    "epochs = 1000\n",
    "\n",
    "w = torch.randn([N], requires_grad=True)\n",
    "print(w.size())\n",
    "x = torch.ones([N], requires_grad=True)\n",
    "print(x.size())\n",
    "b = torch.randn([1], requires_grad=True)\n",
    "\n",
    "for i in range(epochs):\n",
    "\n",
    "    x = torch.ones([N], requires_grad=True)\n",
    "    print\n",
    "    y = 3*x - 2\n",
    "    print(y.size())\n",
    "\n",
    "    y_hat = w*x + b \n",
    "    print(y_hat.size())\n",
    "\n",
    "    loss = torch.sum((y_hat-y)**2)\n",
    "    print('loss',loss)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate*w.grad\n",
    "        b -= learning_rate*b.grad\n",
    "\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hii\n"
     ]
    }
   ],
   "source": [
    "print('hii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
